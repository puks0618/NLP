{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-formula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loose-squad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operating-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(deu):\n",
    "        # open the file\n",
    "        file = open(deu, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quantitative-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spare-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "religious-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solved-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Geh.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['Hi.', 'Hallo!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi.', 'Grüß Gott!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['We took a wrong turn.', 'Wir sind falsch abgebogen.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['We traveled together.', 'Wir waren zusammen auf Reisen.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['We traveled together.', 'Wir sind zusammen gereist.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dress-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Geh',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['Hi', 'Hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi', 'Grüß Gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['We took a wrong turn', 'Wir sind falsch abgebogen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['We traveled together', 'Wir waren zusammen auf Reisen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['We traveled together', 'Wir sind zusammen gereist',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intermediate-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 'geh',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['hi', 'hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['hi', 'grüß gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['we took a wrong turn', 'wir sind falsch abgebogen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['we traveled together', 'wir waren zusammen auf reisen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['we traveled together', 'wir sind zusammen gereist',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "higher-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\tools.py:400: MatplotlibDeprecationWarning: \n",
      "The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n",
      "  if ax.is_first_col():\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unavailable-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intended-holiday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6152\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "national-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10112\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blond-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incredible-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clinical-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "talented-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promotional-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model compilation\n",
    "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "expired-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 169s 2s/step - loss: 4.2857 - val_loss: 2.7683\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.76830, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "63/63 [==============================] - 141s 2s/step - loss: 2.7171 - val_loss: 2.6991\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.76830 to 2.69907, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "63/63 [==============================] - 136s 2s/step - loss: 2.5634 - val_loss: 2.5030\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.69907 to 2.50302, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "63/63 [==============================] - 135s 2s/step - loss: 2.3718 - val_loss: 2.4031\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.50302 to 2.40308, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "63/63 [==============================] - 149s 2s/step - loss: 2.2232 - val_loss: 2.2646\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.40308 to 2.26461, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "63/63 [==============================] - 152s 2s/step - loss: 2.0795 - val_loss: 2.1490\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.26461 to 2.14902, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "63/63 [==============================] - 194s 3s/step - loss: 1.9481 - val_loss: 2.0640\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.14902 to 2.06402, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "63/63 [==============================] - 1228s 20s/step - loss: 1.8341 - val_loss: 1.9883\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.06402 to 1.98834, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "63/63 [==============================] - 231s 4s/step - loss: 1.7279 - val_loss: 1.9107\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.98834 to 1.91065, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "63/63 [==============================] - 238s 4s/step - loss: 1.6338 - val_loss: 1.8383\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.91065 to 1.83827, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "63/63 [==============================] - 210s 3s/step - loss: 1.5227 - val_loss: 1.7796\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.83827 to 1.77960, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "63/63 [==============================] - 229s 4s/step - loss: 1.4444 - val_loss: 1.7034\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.77960 to 1.70336, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "63/63 [==============================] - 208s 3s/step - loss: 1.3390 - val_loss: 1.6477\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.70336 to 1.64771, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "63/63 [==============================] - 193s 3s/step - loss: 1.2556 - val_loss: 1.5985\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.64771 to 1.59854, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "63/63 [==============================] - 1040s 17s/step - loss: 1.1789 - val_loss: 1.5599\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.59854 to 1.55985, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "63/63 [==============================] - 230s 4s/step - loss: 1.1060 - val_loss: 1.5315\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.55985 to 1.53152, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "63/63 [==============================] - 219s 3s/step - loss: 1.0326 - val_loss: 1.4784\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.53152 to 1.47837, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "63/63 [==============================] - 217s 3s/step - loss: 0.9525 - val_loss: 1.4480\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.47837 to 1.44799, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "63/63 [==============================] - 233s 4s/step - loss: 0.8881 - val_loss: 1.4171\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.44799 to 1.41707, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "63/63 [==============================] - 171s 3s/step - loss: 0.8256 - val_loss: 1.4010\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.41707 to 1.40104, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "63/63 [==============================] - 187s 3s/step - loss: 0.7603 - val_loss: 1.3708\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.40104 to 1.37083, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "63/63 [==============================] - 190s 3s/step - loss: 0.6997 - val_loss: 1.3552\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.37083 to 1.35523, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "63/63 [==============================] - 168s 3s/step - loss: 0.6464 - val_loss: 1.3247\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.35523 to 1.32473, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "63/63 [==============================] - 172s 3s/step - loss: 0.5938 - val_loss: 1.3159\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.32473 to 1.31592, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "63/63 [==============================] - 157s 2s/step - loss: 0.5578 - val_loss: 1.2905\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.31592 to 1.29047, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "63/63 [==============================] - 147s 2s/step - loss: 0.5058 - val_loss: 1.2788\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.29047 to 1.27883, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 0.4589 - val_loss: 1.2837\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.27883\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 146s 2s/step - loss: 0.4254 - val_loss: 1.2639\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.27883 to 1.26392, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "63/63 [==============================] - 151s 2s/step - loss: 0.3864 - val_loss: 1.2572\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.26392 to 1.25719, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "63/63 [==============================] - 152s 2s/step - loss: 0.3495 - val_loss: 1.2540\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.25719 to 1.25403, saving model to model.h1.24_jan_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.24_jan_19\\assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.24_jan_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "waiting-template",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "romantic-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "typical-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lined-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "periodic-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sophisticated-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>he reads a good deal</td>\n",
       "      <td>he a  lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414</th>\n",
       "      <td>its a nice party</td>\n",
       "      <td>its a nice party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>hes a frat boy</td>\n",
       "      <td>he is at  guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>thanks for saving me</td>\n",
       "      <td>thank for saving me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>thats weird</td>\n",
       "      <td>thats strange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>they arent dead</td>\n",
       "      <td>you not dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>put on some clothes</td>\n",
       "      <td>take some a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>its pretty ugly</td>\n",
       "      <td>he is quite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>im being watched</td>\n",
       "      <td>ill teach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>they dont seem busy</td>\n",
       "      <td>you look busy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>can i trust them</td>\n",
       "      <td>may i trust you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>tom sang softly</td>\n",
       "      <td>tom stopped quietly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>my head still hurts</td>\n",
       "      <td>im still a french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>thats really sad</td>\n",
       "      <td>thats really sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>please be honest</td>\n",
       "      <td>please be honest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    actual                 predicted\n",
       "4494  he reads a good deal             he a  lot    \n",
       "8414      its a nice party      its a nice party    \n",
       "9031        hes a frat boy          he is at  guy   \n",
       "2604  thanks for saving me   thank for saving me    \n",
       "6386           thats weird       thats strange      \n",
       "4782       they arent dead         you not dead     \n",
       "6784   put on some clothes          take some a     \n",
       "9140       its pretty ugly          he is quite     \n",
       "4991      im being watched           ill teach      \n",
       "4956   they dont seem busy        you look busy     \n",
       "4809      can i trust them       may i trust you    \n",
       "9899       tom sang softly  tom stopped quietly     \n",
       "5027   my head still hurts     im still a french    \n",
       "3955      thats really sad     thats really sad     \n",
       "3979      please be honest     please be honest     "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-secret",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
